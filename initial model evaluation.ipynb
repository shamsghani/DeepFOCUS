{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ba2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# === Imports ===\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, UpSampling2D, Convolution2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check GPU availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"‚úÖ GPU detected: {gpus}\")\n",
    "    try:\n",
    "        # Limit TensorFlow to just the first GPU (optional)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected, training will be on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    train_loss.append(logs['loss'])\n",
    "    val_loss.append(logs['val_loss'])\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(train_loss, label='Train Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Live Training Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "live_plot_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d4bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helper Functions ===\n",
    "\n",
    "def project_01(im):\n",
    "    im = np.squeeze(im)\n",
    "    min_val = im.min()\n",
    "    max_val = im.max()\n",
    "    return (im - min_val)/(max_val - min_val)\n",
    "\n",
    "def normalize_im(im, dmean, dstd):\n",
    "    im = np.squeeze(im)\n",
    "    im_norm = np.zeros(im.shape,dtype=np.float32)\n",
    "    im_norm = (im - dmean)/dstd\n",
    "    return im_norm\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "def matlab_style_gauss2D(shape=(7,7),sigma=1):\n",
    "    m,n = [(ss-1.)/2. for ss in shape]\n",
    "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
    "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
    "    h.astype(dtype=K.floatx())\n",
    "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    h = h*2.0\n",
    "    h = h.astype('float32')\n",
    "    return h\n",
    "\n",
    "psf_heatmap = matlab_style_gauss2D(shape = (7,7),sigma=1)\n",
    "gfilter = tf.reshape(psf_heatmap, [7, 7, 1, 1])\n",
    "\n",
    "def L1L2loss(input_shape):\n",
    "    def bump_mse(heatmap_true, spikes_pred):\n",
    "        # Perform convolution using TensorFlow\n",
    "        heatmap_pred = tf.nn.conv2d(\n",
    "            spikes_pred,\n",
    "            filters=gfilter,\n",
    "            strides=[1, 1, 1, 1],\n",
    "            padding='SAME'\n",
    "        )\n",
    "\n",
    "        # Compute losses\n",
    "        loss_heatmaps = tf.reduce_mean(tf.square(heatmap_true - heatmap_pred))\n",
    "        loss_spikes = tf.reduce_mean(tf.abs(spikes_pred))  # L1 regularization on spikes\n",
    "\n",
    "        return loss_heatmaps + loss_spikes\n",
    "    return bump_mse\n",
    "\n",
    "\n",
    "def conv_bn_relu(nb_filter, rk, ck, name):\n",
    "    def f(input):\n",
    "        conv = Convolution2D(nb_filter, kernel_size=(rk, ck), strides=(1,1),\\\n",
    "                               padding=\"same\", use_bias=False,\\\n",
    "                               kernel_initializer=\"Orthogonal\",name='conv-'+name)(input)\n",
    "        conv_norm = BatchNormalization(name='BN-'+name)(conv)\n",
    "        conv_norm_relu = Activation(activation = \"relu\",name='Relu-'+name)(conv_norm)\n",
    "        return conv_norm_relu\n",
    "    return f\n",
    "\n",
    "def CNN(input,names):\n",
    "    Features1 = conv_bn_relu(32,3,3,names+'F1')(input)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2),name=names+'Pool1')(Features1)\n",
    "    Features2 = conv_bn_relu(64,3,3,names+'F2')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2),name=names+'Pool2')(Features2)\n",
    "    Features3 = conv_bn_relu(128,3,3,names+'F3')(pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2),name=names+'Pool3')(Features3)\n",
    "    Features4 = conv_bn_relu(512,3,3,names+'F4')(pool3)\n",
    "    up5 = UpSampling2D(size=(2, 2),name=names+'Upsample1')(Features4)\n",
    "    Features5 = conv_bn_relu(128,3,3,names+'F5')(up5)\n",
    "    up6 = UpSampling2D(size=(2, 2),name=names+'Upsample2')(Features5)\n",
    "    Features6 = conv_bn_relu(64,3,3,names+'F6')(up6)\n",
    "    up7 = UpSampling2D(size=(2, 2),name=names+'Upsample3')(Features6)\n",
    "    Features7 = conv_bn_relu(32,3,3,names+'F7')(up7)\n",
    "    return Features7\n",
    "\n",
    "def buildModel(input_dim):\n",
    "    input_ = Input (shape = (input_dim))\n",
    "    act_ = CNN (input_,'CNN')\n",
    "    density_pred = Convolution2D(1, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",\\\n",
    "                                  activation=\"linear\", use_bias = False,\\\n",
    "                                  kernel_initializer=\"Orthogonal\",name='Prediction')(act_)\n",
    "    model = Model (inputs= input_, outputs=density_pred)\n",
    "    opt = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss = L1L2loss(input_dim))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üì¶ LOAD & RESHAPE THE DATA\n",
    "# ============================\n",
    "\n",
    "with open(\"from scratch_training_data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "patches = data[\"patches\"]\n",
    "heatmaps = data[\"heatmaps\"]\n",
    "spikes = data[\"spikes\"]  # Optional\n",
    "\n",
    "print(\"‚úÖ Loaded data shapes:\")\n",
    "print(\"patches:\", patches.shape)\n",
    "print(\"heatmaps:\", heatmaps.shape)\n",
    "print(\"spikes:\", spikes.shape)\n",
    "\n",
    "# ============================\n",
    "# üìè NORMALIZATION\n",
    "# ============================\n",
    "# Compute dataset mean & std\n",
    "mean_val = np.mean(patches)\n",
    "std_val = np.std(patches)\n",
    "\n",
    "# Normalize each patch\n",
    "patches = (patches - mean_val) / std_val\n",
    "\n",
    "# Add channel axis\n",
    "patches = patches[..., np.newaxis]\n",
    "heatmaps = heatmaps[..., np.newaxis]\n",
    "\n",
    "print(\"üìê Reshaped & normalized:\")\n",
    "print(\"patches:\", patches.shape)\n",
    "print(\"heatmaps:\", heatmaps.shape)\n",
    "\n",
    "# ============================\n",
    "# ‚úÇÔ∏è TRAIN/TEST SPLIT\n",
    "# ============================\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    patches, heatmaps, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Split:\")\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Validation samples:\", X_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bacd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (208, 208, 1)\n",
    "model = buildModel(input_shape)\n",
    "model.load_weights(r\"weights_RealMicrotubules.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58300897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a sample\n",
    "# pick I random within patches length\n",
    "i = random.randint(1,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c61037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_patch = patches[i]\n",
    "true_heatmap = heatmaps[i]\n",
    "predicted = model.predict(input_patch[np.newaxis])[0]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "# 1. Input Patch\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(input_patch, cmap='gray')\n",
    "plt.title(\"Input Patch\")\n",
    "plt.axis('off')\n",
    "\n",
    "# 2. True Heatmap\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.imshow(true_heatmap, cmap='hot')\n",
    "plt.title(\"True Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "# 3. Predicted Heatmap\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.imshow(predicted, cmap='hot')\n",
    "plt.title(\"Predicted Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "# 4. True Heatmap overlayed on Input Patch\n",
    "# plt.subplot(1, 5, 4)\n",
    "# plt.imshow(input_patch, cmap='gray')\n",
    "# plt.imshow(true_heatmap, cmap='hot', alpha=0.5)\n",
    "# plt.title(\"True Heatmap Overlay\")\n",
    "# plt.axis('off')\n",
    "\n",
    "# # 5. Predicted Heatmap overlayed on True Heatmap\n",
    "# plt.subplot(1, 5, 5)\n",
    "# plt.imshow(true_heatmap, cmap='hot')\n",
    "# plt.imshow(predicted, cmap='cool', alpha=0.5)\n",
    "# plt.title(\"Predicted over True\")\n",
    "# plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Model + Weights ===\n",
    "\n",
    "# Specify the correct input shape\n",
    "input_shape = (208, 208, 1)\n",
    "\n",
    "# Build the model\n",
    "model = buildModel(input_shape)\n",
    "\n",
    "# Load the weights from the .h5 file\n",
    "model.load_weights(r\"DeepSTORM_model_weights_best.hdf5\")\n",
    "\n",
    "print(\"‚úÖ Model loaded and weights applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39060a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a sample\n",
    "input_patch = patches[i]\n",
    "true_heatmap = heatmaps[i]\n",
    "predicted = model.predict(input_patch[np.newaxis])[0]\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "# 1. Input Patch\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(input_patch, cmap='gray')\n",
    "plt.title(\"Input Patch\")\n",
    "plt.axis('off')\n",
    "\n",
    "# 2. True Heatmap\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.imshow(true_heatmap, cmap='hot')\n",
    "plt.title(\"True Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "# 3. Predicted Heatmap\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.imshow(predicted, cmap='hot')\n",
    "plt.title(\"Predicted Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "# # 4. True Heatmap overlayed on Input Patch\n",
    "# plt.subplot(1, 5, 4)\n",
    "# plt.imshow(input_patch, cmap='gray')\n",
    "# plt.imshow(true_heatmap, cmap='hot', alpha=0.5)\n",
    "# plt.title(\"True Heatmap Overlay\")\n",
    "# plt.axis('off')\n",
    "\n",
    "# # 5. Predicted Heatmap overlayed on True Heatmap\n",
    "# plt.subplot(1, 5, 5)\n",
    "# plt.imshow(true_heatmap, cmap='hot')\n",
    "# plt.imshow(predicted, cmap='cool', alpha=0.5)\n",
    "# plt.title(\"Predicted over True\")\n",
    "# plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00205a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Model + Weights ===\n",
    "\n",
    "# Specify the correct input shape\n",
    "input_shape = (208, 208, 1)\n",
    "\n",
    "# Build the model\n",
    "model = buildModel(input_shape)\n",
    "\n",
    "# Load the weights from the .h5 file\n",
    "model.load_weights(r\"weights_SimulatedMicrotubules.hdf5\")\n",
    "\n",
    "print(\"‚úÖ Model loaded and weights applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c611f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_patch = patches[i]\n",
    "true_heatmap = heatmaps[i]\n",
    "predicted = model.predict(input_patch[np.newaxis])[0]\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "# 1. Input Patch\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(input_patch, cmap='gray')\n",
    "plt.title(\"Input Patch\")\n",
    "plt.axis('off')\n",
    "\n",
    "# 2. True Heatmap\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.imshow(true_heatmap, cmap='hot')\n",
    "plt.title(\"True Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "# 3. Predicted Heatmap\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.imshow(predicted, cmap='hot')\n",
    "plt.title(\"Predicted Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "# # 4. True Heatmap overlayed on Input Patch\n",
    "# plt.subplot(1, 5, 4)\n",
    "# plt.imshow(input_patch, cmap='gray')\n",
    "# plt.imshow(true_heatmap, cmap='hot', alpha=0.5)\n",
    "# plt.title(\"True Heatmap Overlay\")\n",
    "# plt.axis('off')\n",
    "\n",
    "# # 5. Predicted Heatmap overlayed on True Heatmap\n",
    "# plt.subplot(1, 5, 5)\n",
    "# plt.imshow(true_heatmap, cmap='hot')\n",
    "# plt.imshow(predicted, cmap='cool', alpha=0.5)\n",
    "# plt.title(\"Predicted over True\")\n",
    "# plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "\n",
    "# Get number of physical CPU cores\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(f\"üñ•Ô∏è CPU cores detected: {num_cores}\")\n",
    "\n",
    "# Configure TensorFlow threading\n",
    "tf.config.threading.set_intra_op_parallelism_threads(num_cores)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(num_cores)\n",
    "\n",
    "print(\"‚úÖ Configured TensorFlow to use all CPU cores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50637ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üèóÔ∏è BUILD THE MODEL\n",
    "# ============================\n",
    "\n",
    "input_shape = X_train.shape[1:]  # (208, 208, 1)\n",
    "model = buildModel(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30caacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# ‚è±Ô∏è CALLBACKS\n",
    "# ============================\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    # patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_finetuned_weights.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cce3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üß† TRAINING\n",
    "# ============================\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=8,\n",
    "    epochs=1,\n",
    "    validation_data=(X_val, y_val),\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stop, checkpoint, live_plot_callback]  # add here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_patch = patches[i]\n",
    "true_heatmap = heatmaps[i]\n",
    "predicted = model.predict(input_patch[np.newaxis])[0]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1); plt.imshow(input_patch, cmap='gray'); plt.title(\"Input Patch\")\n",
    "plt.subplot(1, 3, 2); plt.imshow(true_heatmap, cmap='hot'); plt.title(\"True Heatmap\")\n",
    "plt.subplot(1, 3, 3); plt.imshow(predicted, cmap='hot'); plt.title(\"Predicted Heatmap\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TRP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
